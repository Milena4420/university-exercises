{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Definition (Already Implemented)\n",
    "\n",
    "actions = {\n",
    "    \"up\": (0, 1),\n",
    "    \"left\": (-1, 0),\n",
    "    \"right\": (1, 0),\n",
    "    \"down\": (0, -1),\n",
    "}\n",
    "\n",
    "p_e = 1/3\n",
    "\n",
    "def get_adjacent_positions(position: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    x, y = position\n",
    "    return [\n",
    "            (x, y + 1),\n",
    "            (x, y - 1),\n",
    "            (x + 1, y),\n",
    "            (x - 1, y),\n",
    "    ]\n",
    "\n",
    "class DungeonEnvironment:\n",
    "    def __init__(self):\n",
    "        self.start_pos = (0,0)\n",
    "        self.goal_pos = (3,4)\n",
    "        self.holes = [(0,4), (3,2)]\n",
    "        self.walls = [(0,2), (2,0), (2,2), (2,3)]\n",
    "        self.current_position = (0,0)\n",
    "\n",
    "    def get_echo(self):\n",
    "        for adjacent in get_adjacent_positions(self.current_position):\n",
    "            if adjacent in self.holes:\n",
    "                # hear an each with prob 1/3\n",
    "                if np.random.random() < p_e:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Called at the start of the game.\n",
    "        \"\"\"\n",
    "        self.current_position = self.start_pos\n",
    "\n",
    "    def step(self, action: str) -> Tuple[dict, str, bool]:\n",
    "        \"\"\"\n",
    "        Updates the environment with the action of the agent.\n",
    "        :returns: new observation for the agent, as well as if the game ended and the outcome.\n",
    "        \"\"\"\n",
    "        act_x, act_y = actions[action]\n",
    "        curr_x, curr_y = self.current_position\n",
    "\n",
    "        new_x = curr_x + act_x\n",
    "        new_y = curr_y + act_y\n",
    "\n",
    "        # we bump if we go into a wall, or if we go out of bound\n",
    "        if (new_x, new_y) in self.walls or not (0<=new_x<=4 and 0<=new_y<=4):\n",
    "            bump = True\n",
    "        else:\n",
    "            # if we do not bump, update the position.\n",
    "            bump = False\n",
    "            self.current_position = (new_x, new_y)\n",
    "\n",
    "        observation = {\n",
    "            \"echo\" : self.get_echo(),\n",
    "            \"position\": self.current_position,\n",
    "        }\n",
    "\n",
    "        if self.current_position == self.goal_pos:\n",
    "            outcome = \"Escaped\"\n",
    "            terminated = True\n",
    "        elif self.current_position in self.holes:\n",
    "            outcome = \"Fell into hole\"\n",
    "            terminated = True\n",
    "\n",
    "        else:\n",
    "            outcome = None\n",
    "            terminated = False\n",
    "\n",
    "        return observation, outcome, terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belief State (To be completed)\n",
    "\n",
    "\n",
    "class BeliefState:\n",
    "    \"\"\"\n",
    "    Maintains what we believe, using the knowledge base.\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_hole_belief=0.5):\n",
    "        self.hole_beliefs = {\n",
    "            (0, 4): initial_hole_belief,\n",
    "            (3, 2): initial_hole_belief,\n",
    "            (4, 0): initial_hole_belief,\n",
    "        }  # list of positions where we sensed echoes\n",
    "        self.current_position = (0, 0)\n",
    "\n",
    "    def update(self, echo: bool, position: Tuple[int, int]):\n",
    "        \"\"\"\n",
    "        :param echo: did we hear an echo ?\n",
    "        :param position: our current position.\n",
    "        \"\"\"\n",
    "        self.current_position = position\n",
    "        \n",
    "        new_belief = self.hole_beliefs.copy()\n",
    "\n",
    "        for adjacent_pos in get_adjacent_positions(position):\n",
    "            if adjacent_pos not in self.hole_beliefs:\n",
    "                continue\n",
    "            # We are adjacent to a hole position\n",
    "            # TODO:\n",
    "            # update the belief\n",
    "                \n",
    "        self.hole_beliefs = new_belief\n",
    "        \n",
    "        \n",
    "    def visualise(self):\n",
    "        grid_size = (5, 5)\n",
    "        grid = np.zeros(grid_size)\n",
    "\n",
    "        for x in range(5):\n",
    "            for y in range(5):\n",
    "                grid[y, x] = self.hole_beliefs.get((x,y), 0)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(grid, cmap=\"viridis\", origin=\"lower\", extent=[0, 5, 0, 5])\n",
    "\n",
    "        plt.colorbar(label=\"Hole probability\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.xticks(range(0, 6))\n",
    "        plt.yticks(range(0, 6))\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.6, color=\"black\")\n",
    "        plt.title(\"Holes belief\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for running any agent on the dungeon environment (Already implemented)\n",
    "def play_game(policy, belief_state):\n",
    "    terminated = False\n",
    "    environment = DungeonEnvironment()\n",
    "    environment.reset()\n",
    "    num_steps = 0\n",
    "    trajectory = []\n",
    "    while not terminated:\n",
    "        action = policy(belief_state)\n",
    "        observation, outcome, terminated = environment.step(action)\n",
    "        belief_state.update(**observation)\n",
    "        trajectory.append(environment.current_position)\n",
    "        num_steps += 1\n",
    "\n",
    "        if num_steps >= 500:\n",
    "            print(\"Check your code, probably your agent is stuck somewhere\")\n",
    "            outcome = \"Timeout\"\n",
    "            terminated = True\n",
    "    \n",
    "    return outcome, trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent definitions\n",
    "\n",
    "# Naive agent Example \n",
    "def random_agent(belief) -> str:\n",
    "    \"\"\"\n",
    "    This is a naive agent, picking actions randomly.\n",
    "    \"\"\"\n",
    "    action_names = list(actions.keys())\n",
    "    return np.random.choice(action_names)\n",
    "\n",
    "\n",
    "def smarter_agent(belief) -> str:\n",
    "    \"\"\"\n",
    "    This function selects a new action based on the belief state.\n",
    "    :param belief: Current belief state.\n",
    "    :return: action picked by the policy (e.g., \"up\"):\n",
    "    \"\"\"\n",
    "    # TODO (optional): try implementing a smarter agent\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "belief_state = BeliefState()\n",
    "\n",
    "print(\"Initial belief:\")\n",
    "belief_state.visualise()\n",
    "\n",
    "for episode in range(1, 21):\n",
    "    outcome, trajectory = play_game(random_agent, belief_state)\n",
    "    \n",
    "    print(f\"Episode {episode}:\")\n",
    "    print(f\"The game ended in {len(trajectory)} steps with the following outcome: {outcome}.\")\n",
    "    \n",
    "    print(\"Belief:\")\n",
    "    belief_state.visualise()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
